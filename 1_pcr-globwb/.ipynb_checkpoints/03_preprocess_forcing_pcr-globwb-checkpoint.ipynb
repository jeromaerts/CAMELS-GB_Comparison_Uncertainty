{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b44c21-1c04-4e30-ac92-39cb9453639b",
   "metadata": {},
   "source": [
    "# Pre-process pcr-globwb forcing for CAMELS-GB in parallel\n",
    "## CEH-GEAR: pr, CHESS-PE: pet, CHESS-met: tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5eb70a-f6f2-4ec7-8f7d-b5c2d9a668a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b71e39-8d5e-4a18-9bfd-247cc60ff8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import iris\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "import rasterio\n",
    "import rioxarray\n",
    "\n",
    "from esmvalcore.preprocessor import regrid\n",
    "from pathos.threading import ThreadPool as Pool\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5866131c-6415-4284-ae3d-6517cb631aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snellius paths\n",
    "ROOT = Path('/gpfs/work1/0/wtrcycle/users/jaerts/camels_uk/')\n",
    "AUXDATA = Path(f\"{ROOT}/aux_data\")\n",
    "FORCING = Path(f'{ROOT}/forcing/')\n",
    "MODELS = Path(f'{ROOT}/pcr-globwb/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f230010d-cd9e-4b0e-8945-2f7845b52ea4",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac19a632-03a8-4bab-b01c-4cf3f7bdbdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time Period\n",
    "start_year = \"2000\"\n",
    "end_year = \"2017\"\n",
    "\n",
    "# Get available basin IDs wflow_sbm\n",
    "basin_dirs = glob(f'{MODELS}/*')\n",
    "basin_ids = [s.split('/')[-1] for s in basin_dirs]\n",
    "basin_ids.remove('uk')\n",
    "basin_ids.sort()\n",
    "\n",
    "# Amount of available cores\n",
    "cores_available = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1b5eb9-bb7c-4be8-8d49-2b2f8a540c55",
   "metadata": {},
   "source": [
    "# Preprocess forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938bfe74-eb17-4e48-ab60-7eb6372ac592",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_id = 'uk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7f097b-8e23-44e3-8734-b6d9b3df0ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set basin directory\n",
    "BASINDIR = f'{MODELS}/{basin_id}/'\n",
    "\n",
    "# Open netCDF file as an example grid from the model directory\n",
    "ds = xr.open_rasterio(f'{BASINDIR}/{basin_id}_30sec_clone.map')\n",
    "cube_example = ds.squeeze('band').drop('band').to_iris()\n",
    "\n",
    "cube_example.coord('y').rename('latitude')\n",
    "cube_example.coord('x').rename('longitude')\n",
    "\n",
    "# Guess bounds   \n",
    "cube_example.coord('latitude').guess_bounds()\n",
    "cube_example.coord('longitude').guess_bounds()\n",
    "\n",
    "cube_example.coord('latitude').units = 'degrees'\n",
    "cube_example.coord('longitude').units = 'degrees'\n",
    "\n",
    "# Loop forcing variables\n",
    "for variable in ['pet','tas','pr']:\n",
    "    print(variable)\n",
    "\n",
    "    # Load forcing file\n",
    "    da_clim = xr.open_dataset(glob(f'{FORCING}/*{variable}*')[0])[variable]\n",
    "\n",
    "    # Create climatology\n",
    "    da_clim = da_clim.sel(time=slice('2000', '2007'))\n",
    "    da_clim = da_clim.convert_calendar('365_day')\n",
    "    da_clim = da_clim.groupby(\"time.dayofyear\").mean('time')\n",
    "    da_clim = da_clim.assign_coords(dayofyear=xr.date_range('2007-01-01','2007-12-31'))\n",
    "    da_clim = da_clim.rename({'dayofyear':'time'})\n",
    "\n",
    "    # Convert to cube\n",
    "    cube_forcing = da_clim.to_iris()\n",
    "\n",
    "    # Guess bounds\n",
    "    cube_forcing.coord('latitude').guess_bounds()\n",
    "    cube_forcing.coord('longitude').guess_bounds()\n",
    "\n",
    "    # Regrid forcing file to example grid using conservative method\n",
    "    print('Regridding...')\n",
    "    cube_out = regrid(cube_forcing, cube_example, scheme='area_weighted')\n",
    "\n",
    "    # Rename Coords\n",
    "    cube_out.coord('latitude').rename('lat')\n",
    "    cube_out.coord('longitude').rename('lon')\n",
    "\n",
    "    # Convert to xarray\n",
    "    da_clim = xr.DataArray.from_iris(cube_out)\n",
    "\n",
    "    cube_forcing = None\n",
    "    cube_out = None\n",
    "    \n",
    "    \n",
    "    # Set attributes\n",
    "    da_clim.lon.attrs = {'long_name': 'longitude',\n",
    "                    'standard_name': 'longitude',\n",
    "                    'units': 'degrees'}\n",
    "    da_clim.lat.attrs = {'long_name': 'latitude',\n",
    "                    'standard_name': 'latitude',\n",
    "                    'units': 'degrees'}   \n",
    "    da_clim.time.attrs = {'standard_name': 'time',\n",
    "                     'long_name': 'time'}\n",
    "    # Convert to dataset\n",
    "    da_clim = da_clim.to_dataset()\n",
    "\n",
    "    # convert to m*day\n",
    "    if variable == 'pr':\n",
    "        da_clim = da_clim * 0.001\n",
    "    if variable == 'pr':\n",
    "        da_clim = da_clim * 0.001\n",
    "    if variable == 'tas':\n",
    "        pass\n",
    "\n",
    "    # Output filename\n",
    "    output_fname = f'{BASINDIR}/ceh-gear_chess_camels-gb_{basin_id}_{variable}_clim2000-2007.nc'\n",
    "\n",
    "    # Remove existing file\n",
    "    if output_fname:\n",
    "        OUTPUT = Path(output_fname)\n",
    "        OUTPUT.unlink(output_fname)\n",
    "\n",
    "    # Save to netcdf\n",
    "    write_job = da_clim.to_netcdf(output_fname, encoding={f'{variable}': {'_FillValue': -9999, 'missing_value':-9999}}, compute=False)\n",
    "    with ProgressBar():\n",
    "        write_job.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5637d972-81da-402c-9da3-e0da3e5a5fb6",
   "metadata": {},
   "source": [
    "# Combine variables into single NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d673818-24a3-43b7-8b54-7719083d1fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in ['pet','pr','tas']:\n",
    "    print(variable)\n",
    "    basin_id = 'uk'\n",
    "    files = glob.glob(f\"/gpfs/work1/0/wtrcycle/users/jaerts/camels_uk/pcr-globwb/uk/ceh-gear_chess_camels-gb_uk_{variable}_*.nc\")\n",
    "    ds = xr.open_mfdataset(files, chunks={'time':1})\n",
    "    # Output filename\n",
    "    output_fname = f'/gpfs/work1/0/wtrcycle/users/jaerts/camels_uk/pcr-globwb/uk/ceh-gear_chess_camels-gb_{basin_id}_{variable}_clim2000-2007_2017.nc'\n",
    "\n",
    "    # Remove existing file\n",
    "    if output_fname:\n",
    "        OUTPUT = Path(output_fname)\n",
    "        OUTPUT.unlink(output_fname)\n",
    "\n",
    "    # Save to netcdf\n",
    "    write_job = ds.to_netcdf(output_fname, encoding={f'{variable}': {'_FillValue': -9999, 'missing_value':-9999}}, compute=False)\n",
    "    with ProgressBar():\n",
    "        write_job.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
