{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec810938-a52d-42a3-b829-301e70cdb79a",
   "metadata": {},
   "source": [
    "# Streamflow analyses PCR-GLOBWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "359ee338-9aba-4a61-9bfd-4fc4acdfebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hydroeval\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee5d18e-9e9f-4acf-a45c-3810aac44dfa",
   "metadata": {},
   "source": [
    "# Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "644671e1-7a0a-4fb4-80e1-f20d97b45edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "ROOT = Path('/gpfs/work1/0/wtrcycle/users/jaerts/camels_uk/')\n",
    "MODELS = Path(f'{ROOT}/pcr-globwb/')\n",
    "AUXDATA = Path(f'{ROOT}/aux_data/')\n",
    "OBSDIR = Path(f\"{AUXDATA}/CAMELS-GB/data/timeseries/\")\n",
    "OUTPUT = Path(f'{ROOT}/results/pcr-globwb/evaluation/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2668b105-2071-40f1-b5ab-42b89a5a6c62",
   "metadata": {},
   "source": [
    "# UK CloneMap Run\n",
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f579f059-f76d-45a4-9674-898a8d7de152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get available basin IDs\n",
    "basin_dirs = glob(f'{MODELS}/*')\n",
    "basin_ids = [s.split('/')[-1] for s in basin_dirs]\n",
    "basin_ids.remove('uk')\n",
    "basin_ids.sort()\n",
    "\n",
    "# Time period (drop first year)\n",
    "start_date = '2008-01-01'\n",
    "end_date   = '2015-09-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7c83f40-34a5-4dc4-8eb4-abbca3bc38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_ids.remove('18017')\n",
    "basin_ids.remove('18018')\n",
    "# basin_ids.remove('21006')\n",
    "# basin_ids.remove('28117')\n",
    "# basin_ids.remove('39127')\n",
    "# basin_ids.remove('41013')\n",
    "# basin_ids.remove('41023')\n",
    "# basin_ids.remove('46005')\n",
    "# basin_ids.remove('47018')\n",
    "# basin_ids.remove('54003')\n",
    "# basin_ids.remove('54028')\n",
    "# basin_ids.remove('54034')\n",
    "# basin_ids.remove('54038')\n",
    "# basin_ids.remove('54060')\n",
    "# basin_ids.remove('67010')\n",
    "# basin_ids.remove('74006')\n",
    "# basin_ids.remove('76011')\n",
    "# basin_ids.remove('80136')\n",
    "# basin_ids =  basin_ids[565:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc9ae4c-6de6-48d0-9d5c-ad93c1456e84",
   "metadata": {},
   "source": [
    "## Retrieve data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4534a19-c628-48e0-9c6e-2a7dfafdc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_location(basin_id):\n",
    "    # Load location file\n",
    "    location_file = f\"{AUXDATA}/CAMELS-GB/data/CAMELS_GB_topographic_attributes.csv\"\n",
    "    df_loc = pd.read_csv(location_file, index_col='gauge_id')\n",
    "    \n",
    "    # Select basin_ids and retrieve lat lon\n",
    "    df_loc = df_loc.loc[int(basin_id)]\n",
    "    latlon = (df_loc.gauge_lat, df_loc.gauge_lon)\n",
    "\n",
    "    return latlon\n",
    "\n",
    "def get_observations(basin_id, start_date, end_date):\n",
    "    # Set observation file\n",
    "    obs_file = glob(f'{OBSDIR}/*_{basin_id}_*.csv')[0]\n",
    "    \n",
    "    # Load observation dataframe\n",
    "    df_obs = pd.read_csv(obs_file, parse_dates=True, index_col='date')\n",
    "    \n",
    "    # Select calibration period (drop first year)\n",
    "    mask = (df_obs.index > start_date) & (df_obs.index <= end_date)\n",
    "    df_obs = df_obs.loc[mask]\n",
    "    \n",
    "    return df_obs\n",
    "\n",
    "def get_simulations(basin_id, start_date, end_date):\n",
    "    # Load simulation results\n",
    "    sim_file = f\"{MODELS}/uk/netcdf/discharge_dailyTot_output.nc\"\n",
    "    ds_sim = xr.open_dataset(sim_file)\n",
    "\n",
    "    # Get station location\n",
    "    latlon = get_station_location(basin_id)\n",
    "\n",
    "    # Extract station location timeseries\n",
    "    ds_sim = ds_sim.discharge.sel(lat=latlon[0], lon=latlon[1], method='nearest')\n",
    "\n",
    "    # Convert to dataframe\n",
    "    df_sim = ds_sim.to_dataframe()\n",
    "\n",
    "    # Select calibration period (drop first year)\n",
    "    mask = (df_sim.index > start_date) & (df_sim.index <= end_date)\n",
    "    df_sim = df_sim.loc[mask]\n",
    "\n",
    "    # Rename column\n",
    "    df_sim = df_sim.drop(columns=['lat','lon'])\n",
    "    df_sim = df_sim.rename(columns={'discharge': f'sim'})\n",
    "\n",
    "    return df_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e433e600-53f0-4839-be2b-94ce6f7b876b",
   "metadata": {},
   "source": [
    "# Adjust station location to river network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "781d8329-470c-4a6b-ac68-77cf4e868ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjusted_station_location_simulations(basin_id, start_date, end_date):\n",
    "\n",
    "     # Get station_location\n",
    "    station_lat, station_lon = get_station_location(basin_id)\n",
    "\n",
    "    # Create 4 pixel buffer\n",
    "    buffer = 0.0083333\n",
    "    min_lat = station_lat-buffer\n",
    "    max_lat = station_lat+buffer\n",
    "    min_lon = station_lon-buffer\n",
    "    max_lon = station_lon+buffer\n",
    "\n",
    "    # Load simulation file\n",
    "    sim_file = f\"{MODELS}/uk/netcdf/discharge_dailyTot_output.nc\"\n",
    "    ds = xr.open_dataset(sim_file)\n",
    "    da = ds.sel(lat=slice(max_lat,min_lat), lon=slice(min_lon,max_lon)).discharge\n",
    "\n",
    "    # Load observation file\n",
    "    df_obs = get_observations(basin_id, start_date, end_date)\n",
    "\n",
    "    da = abs(da - df_obs.discharge_vol.mean())\n",
    "    da_max = da.where(da==da.min(), drop=True).squeeze()\n",
    "\n",
    "    # Select pixel with highest discharge value\n",
    "    print(np.count_nonzero(da_max.lat.values))\n",
    "    if np.count_nonzero(da_max.lat.values) > 1:\n",
    "         df_sim = ds.discharge.sel(lat=da_max.lat.values[0], lon=da_max.lon.values[0]).to_dataframe()\n",
    "    else:\n",
    "        df_sim = ds.discharge.sel(lat=da_max.lat.values, lon=da_max.lon.values).to_dataframe()\n",
    "\n",
    "    # Select calibration period (drop first year)\n",
    "    df_sim = df_sim.reset_index()\n",
    "    df_sim = df_sim.set_index('time')\n",
    "    mask = (df_sim.index > start_date) & (df_sim.index <= end_date)\n",
    "    df_sim = df_sim.loc[mask]\n",
    "\n",
    "    # Rename column\n",
    "    df_sim = df_sim.drop(columns=['lat','lon'])\n",
    "    df_sim = df_sim.rename(columns={'discharge': f'sim'})\n",
    "    \n",
    "    return df_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac23101-a2bb-4c83-89ba-87154eabfa2f",
   "metadata": {},
   "source": [
    "## Calculate objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df253e79-497a-4475-9608-ead2e5c98962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_objective_functions(basin_id, df_sim, df_obs):\n",
    "    \n",
    "    # Create empty dataframe and lists\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Combine obs and sim because of nan values\n",
    "    df_eval = df_obs.discharge_vol.to_frame().join(df_sim)\n",
    "\n",
    "    # Calculate objective functions and round\n",
    "    nse = hydroeval.evaluator(hydroeval.nse, df_eval[f'sim'], df_eval.discharge_vol, axis=1)\n",
    "    nse = np.round(nse[0], 4)\n",
    "\n",
    "    kge_2009 = hydroeval.evaluator(hydroeval.kge, df_eval[f'sim'], df_eval.discharge_vol, axis=1)\n",
    "    kge_2009 = np.round(kge_2009[0][0], 4)\n",
    "\n",
    "    kge_2012 = hydroeval.evaluator(hydroeval.kgeprime, df_eval[f'sim'], df_eval.discharge_vol, axis=1)\n",
    "    kge_2012 = np.round(kge_2012[0][0], 4)\n",
    "\n",
    "    kge_np = hydroeval.evaluator(hydroeval.kgenp, df_eval[f'sim'], df_eval.discharge_vol, axis=1)\n",
    "    kge_np_value = np.round(kge_np[0][0], 4)\n",
    "    kge_np_r = np.round(kge_np[0][1], 4)\n",
    "    kge_np_alpha = np.round(kge_np[0][2], 4)\n",
    "    kge_np_beta = np.round(kge_np[0][3], 4)\n",
    "\n",
    "    df['basin_id'] = [basin_id]\n",
    "    df['nse']      = [nse]\n",
    "    df['kge_2009'] = [kge_2009]\n",
    "    df['kge_2012'] = [kge_2012]\n",
    "    df['kge_np']   = [kge_np_value]\n",
    "\n",
    "    df['kge_np_r'] = [kge_np_r]\n",
    "    df['kge_np_alpha'] = [kge_np_alpha]\n",
    "    df['kge_np_beta'] = [kge_np_beta]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da42b65-b82d-4cda-b76c-39cfbe9b77dd",
   "metadata": {},
   "source": [
    "# Streamflow analyses with adjusted station location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5725ae5b-e05e-40ec-a2a0-a2fd913beff6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74006\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:80: RuntimeWarning: invalid value encountered in divide\n",
      "  r = r_num / r_den\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:126: RuntimeWarning: invalid value encountered in divide\n",
      "  r = r_num / r_den\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  gamma = ((np.std(simulations, axis=0, dtype=np.float64) / sim_mean)\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  simulations / (simulations.shape[0] * np.mean(simulations, axis=0,\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:80: RuntimeWarning: invalid value encountered in divide\n",
      "  r = r_num / r_den\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:126: RuntimeWarning: invalid value encountered in divide\n",
      "  r = r_num / r_den\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  gamma = ((np.std(simulations, axis=0, dtype=np.float64) / sim_mean)\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  simulations / (simulations.shape[0] * np.mean(simulations, axis=0,\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:80: RuntimeWarning: invalid value encountered in divide\n",
      "  r = r_num / r_den\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:126: RuntimeWarning: invalid value encountered in divide\n",
      "  r = r_num / r_den\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  gamma = ((np.std(simulations, axis=0, dtype=np.float64) / sim_mean)\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  simulations / (simulations.shape[0] * np.mean(simulations, axis=0,\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:80: RuntimeWarning: invalid value encountered in divide\n",
      "  r = r_num / r_den\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:126: RuntimeWarning: invalid value encountered in divide\n",
      "  r = r_num / r_den\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  gamma = ((np.std(simulations, axis=0, dtype=np.float64) / sim_mean)\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  simulations / (simulations.shape[0] * np.mean(simulations, axis=0,\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:80: RuntimeWarning: invalid value encountered in divide\n",
      "  r = r_num / r_den\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:126: RuntimeWarning: invalid value encountered in divide\n",
      "  r = r_num / r_den\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  gamma = ((np.std(simulations, axis=0, dtype=np.float64) / sim_mean)\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  simulations / (simulations.shape[0] * np.mean(simulations, axis=0,\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:80: RuntimeWarning: invalid value encountered in divide\n",
      "  r = r_num / r_den\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:126: RuntimeWarning: invalid value encountered in divide\n",
      "  r = r_num / r_den\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  gamma = ((np.std(simulations, axis=0, dtype=np.float64) / sim_mean)\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  simulations / (simulations.shape[0] * np.mean(simulations, axis=0,\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:80: RuntimeWarning: invalid value encountered in divide\n",
      "  r = r_num / r_den\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:126: RuntimeWarning: invalid value encountered in divide\n",
      "  r = r_num / r_den\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  gamma = ((np.std(simulations, axis=0, dtype=np.float64) / sim_mean)\n",
      "/home/jaerts/miniconda3/envs/wflow_state_flux/lib/python3.10/site-packages/hydroeval/objective_functions.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  simulations / (simulations.shape[0] * np.mean(simulations, axis=0,\n"
     ]
    }
   ],
   "source": [
    "for i, basin_id in enumerate(basin_ids):\n",
    "    print(basin_id)\n",
    "\n",
    "    df_sim = get_adjusted_station_location_simulations(basin_id, start_date, end_date)\n",
    "    df_obs = get_observations(basin_id, start_date, end_date)\n",
    "\n",
    "    df_sim.to_csv(f'{OUTPUT}/{basin_id}_evaluation_simulations_adjusted_location_4px.csv')\n",
    "    df_obs.to_csv(f'{OUTPUT}/{basin_id}_evaluation_observations.csv', index=False)   \n",
    "\n",
    "    # Calculate objective function for each water year and take average\n",
    "    years = list(range(int(start_date[:4]), int(end_date[:4])))\n",
    "\n",
    "    objective_dfs = []\n",
    "    for year in years:\n",
    "        start_year = f'{year}-10-01'\n",
    "        end_year = f'{year+1}-09-30'\n",
    "\n",
    "        # Select water year\n",
    "        mask_sim = (df_sim.index >= start_year) & (df_sim.index <= end_year)\n",
    "        mask_obs = (df_obs.index >= start_year) & (df_obs.index <= end_year)\n",
    "\n",
    "        df_sim_year = df_sim.loc[mask_sim]\n",
    "        df_obs_year = df_obs.loc[mask_obs]\n",
    "\n",
    "        # Calculate objective function\n",
    "        df_objective = calculate_objective_functions(basin_id, df_sim_year, df_obs_year)\n",
    "        objective_dfs.append(df_objective)\n",
    "\n",
    "    # Merge water years objective values and take the mean value\n",
    "    df = pd.concat(objective_dfs,axis=1)\n",
    "    df = df.groupby(level=0,axis=1).mean()\n",
    "    df = df.sort_values('kge_np', ascending=False)\n",
    "    df['basin_id'] = [basin_id] * len(df)\n",
    "    df.to_csv(f'{OUTPUT}/{basin_id}_evaluation_objective_functions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea806b-aef0-4266-88af-e326e91fd785",
   "metadata": {},
   "source": [
    "# Create overview dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "77c00192-6871-45da-bd6f-97f14a3a91c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(f'{OUTPUT}/*_evaluation_objective_functions_adjusted_location_4px.csv')\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "    \n",
    "df_out = pd.concat(dataframes)\n",
    "df_out.to_csv(f'{ROOT}/results/pcr-globwb/evaluation_overview_pcrglobwb_adjusted_loc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd3798f-033d-49f8-8bce-99f5dd7f4b8d",
   "metadata": {},
   "source": [
    "# Gumboot prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "4a03870b-f4a2-4910-9a30-0b4c48dd7cba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655\r"
     ]
    }
   ],
   "source": [
    "for i, basin_id in enumerate(basin_ids):\n",
    "    print(i, end='\\r')\n",
    "\n",
    "    df_sim = pd.read_csv(f\"{OUTPUT}/{basin_id}_evaluation_simulations_adjusted_location_4px.csv\")\n",
    "    df_sim['time'] = pd.to_datetime(df_sim['time'])\n",
    "    df_sim = df_sim.set_index('time')\n",
    "    \n",
    "    df_obs = get_observations(basin_id, start_date, end_date)\n",
    "\n",
    "    df_eval = df_sim.join(df_obs.discharge_vol)\n",
    "    df_eval = df_eval.reset_index()\n",
    "    df_eval = df_eval.rename(columns={'time':'date', 'discharge_vol':'obs'})\n",
    "    if df_eval.columns[0] == 'index':\n",
    "        df_eval = df_eval.rename(columns={'index':'date'})\n",
    "    \n",
    "    df_eval = df_eval.set_index('date')\n",
    "    df_eval.to_csv(f'{OUTPUT}/{basin_id}_evaluation_simulations_adjusted_location_4px_gumboot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f857409-db85-41ad-b986-c84c58539efe",
   "metadata": {},
   "source": [
    "# Calculate for flow categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da049a79-290d-4080-b9d7-46578f2e315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flow_category_simulations(basin_id, flow_category, start_date, end_date):\n",
    "    dataframes = []\n",
    "\n",
    "    # Set simulation file\n",
    "    sim_file = glob(f'{ROOT}/results/categories/{category}/{basin_id}_model_difference.csv')[0]\n",
    "    \n",
    "    # Load simulation dataframe\n",
    "    df = pd.read_csv(sim_file, parse_dates=True, index_col='time')\n",
    "\n",
    "    # Select calibration period (drop first year)\n",
    "    mask = (df.index > start_date) & (df.index <= end_date)\n",
    "    df = df.loc[mask]\n",
    "\n",
    "    # Rename column\n",
    "    df = df.rename(columns={'Q_1': f'evaluation'})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_flow_category_observations(basin_id, start_date, end_date):\n",
    "    # Set observation file\n",
    "    obs_file = glob(f'{OBSDIR}/*_{basin_id}_*.csv')[0]\n",
    "    \n",
    "    # Load observation dataframe\n",
    "    df_obs = pd.read_csv(obs_file, parse_dates=True, index_col='date')\n",
    "    \n",
    "    # Select calibration period (drop first year)\n",
    "    mask = (df_obs.index > start_date) & (df_obs.index <= end_date)\n",
    "    df_obs = df_obs.loc[mask]\n",
    "    \n",
    "    return df_obs\n",
    "\n",
    "\n",
    "def get_simulations(basin_id, start_date, end_date):\n",
    "    # Load simulation results\n",
    "    sim_file = f\"{MODELS}/uk/netcdf/discharge_dailyTot_output.nc\"\n",
    "    ds_sim = xr.open_dataset(sim_file)\n",
    "\n",
    "    # Get station location\n",
    "    latlon = get_station_location(basin_id)\n",
    "\n",
    "    # Extract station location timeseries\n",
    "    ds_sim = ds_sim.discharge.sel(lat=latlon[0], lon=latlon[1], method='nearest')\n",
    "\n",
    "    # Convert to dataframe\n",
    "    df_sim = ds_sim.to_dataframe()\n",
    "\n",
    "    # Select calibration period (drop first year)\n",
    "    mask = (df_sim.index > start_date) & (df_sim.index <= end_date)\n",
    "    df_sim = df_sim.loc[mask]\n",
    "\n",
    "    # Rename column\n",
    "    df_sim = df_sim.drop(columns=['lat','lon'])\n",
    "    df_sim = df_sim.rename(columns={'discharge': f'sim'})\n",
    "\n",
    "    return df_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb2381a-cfb1-4e62-8fc9-093971d2b9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f09a3-a19d-462c-827a-2c719e582fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db604135-28d0-4ef1-9a4b-2be4ae945ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca4b63-cbcd-4e52-a9e0-46f8d634e1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b5e65f-2182-4b7f-906c-5f1d437c968f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a7125-9295-4afa-adea-69c10176df6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6af490-b067-4211-8549-701d4bc9843f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f774472-fb32-43f4-8266-1e5e4445782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, basin_id in enumerate(basin_ids):\n",
    "    print(basin_id)\n",
    "\n",
    "    df_sim = get_adjusted_station_location_simulations(basin_id, start_date, end_date)\n",
    "    df_obs = get_observations(basin_id, start_date, end_date)\n",
    "\n",
    "    df_sim.to_csv(f'{OUTPUT}/{basin_id}_evaluation_simulations_adjusted_location_4px.csv')\n",
    "    df_obs.to_csv(f'{OUTPUT}/{basin_id}_evaluation_observations.csv', index=False)   \n",
    "\n",
    "    # Calculate objective function for each water year and take average\n",
    "    years = list(range(int(start_date[:4]), int(end_date[:4])))\n",
    "\n",
    "    objective_dfs = []\n",
    "    for year in years:\n",
    "        start_year = f'{year}-10-01'\n",
    "        end_year = f'{year+1}-09-30'\n",
    "\n",
    "        # Select water year\n",
    "        mask_sim = (df_sim.index >= start_year) & (df_sim.index <= end_year)\n",
    "        mask_obs = (df_obs.index >= start_year) & (df_obs.index <= end_year)\n",
    "\n",
    "        df_sim_year = df_sim.loc[mask_sim]\n",
    "        df_obs_year = df_obs.loc[mask_obs]\n",
    "\n",
    "        # Calculate objective function\n",
    "        df_objective = calculate_objective_functions(basin_id, df_sim_year, df_obs_year)\n",
    "        objective_dfs.append(df_objective)\n",
    "\n",
    "    # Merge water years objective values and take the mean value\n",
    "    df = pd.concat(objective_dfs,axis=1)\n",
    "    df = df.groupby(level=0,axis=1).mean()\n",
    "    df = df.sort_values('kge_np', ascending=False)\n",
    "    df['basin_id'] = [basin_id] * len(df)\n",
    "    df.to_csv(f'{OUTPUT}/{basin_id}_evaluation_objective_functions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b54598-5f28-4788-85ae-b48f50983317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd8c312-9369-4f3c-9c84-e462bdf77d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c53a236-c831-4e50-aea7-6f20167f4c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885d01b-c097-4e73-8685-9b9858a8772c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aeb947-524f-4b52-9982-65e9b94f90e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf3cb5b-e984-4268-98cc-75751851fbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a534068-1b0c-4204-8ee8-48f4f4bd0400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a996eea-3477-445f-a759-9caa71c6ce23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a8381c-8a62-455b-b31f-924147040e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c847242-c564-4819-8deb-972bd2a1f32e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
