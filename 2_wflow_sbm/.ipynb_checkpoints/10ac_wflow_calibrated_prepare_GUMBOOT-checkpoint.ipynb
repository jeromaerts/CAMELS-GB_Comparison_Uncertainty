{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9df87b-2bab-4d25-ab02-7ab00531a758",
   "metadata": {},
   "source": [
    "# Prepare calibrated wflow simulation timeseries for the GUMBOOT package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788eee4-9f93-4b74-b466-b7a6fdbeec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b389c6-b794-4fae-b725-cc97f5f7edad",
   "metadata": {},
   "source": [
    "## Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26659f8-ad9a-4c0a-ae69-3ae59312d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "ROOT = Path(\"/gpfs/work1/0/wtrcycle/users/jaerts/camels_uk/\")\n",
    "MODELS = Path(f'{ROOT}/wflow/data/')\n",
    "AUXDATA = Path(f\"{ROOT}/aux_data\")\n",
    "OBSDIR = Path(f\"{AUXDATA}/CAMELS-GB/data/timeseries/\")\n",
    "OUTPUT = Path(f\"{ROOT}/results/wflow_sbm/evaluation_period_calibrated/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2f01f2-37a5-4847-be29-e37ccc275ba1",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed83f0c-74bb-4241-9008-b5425fd71dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get available basin IDs wflow_sbm\n",
    "basin_dirs = glob(f'{MODELS}/*')\n",
    "basin_ids = [s.split('/')[-1] for s in basin_dirs]\n",
    "basin_ids.sort()\n",
    "\n",
    "\n",
    "# Period (drop first year)\n",
    "start_date = '2008-10-01'\n",
    "end_date   = '2015-09-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce92913-6eb7-41bd-8244-9ae52e14fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "basins = []\n",
    "exists = []\n",
    "\n",
    "for basin_id in basin_ids:\n",
    "    basins.append(basin_id)\n",
    "\n",
    "    # check if file exists\n",
    "    sim_file = Path(f'{MODELS}/{basin_id}/evaluation/output.csv')\n",
    "    if sim_file.is_file() is False:\n",
    "        exists.append(False)\n",
    "    else:\n",
    "        df_sim = pd.read_csv(sim_file)\n",
    "    \n",
    "        # Check if csv containes output\n",
    "        if len(df_sim) == 0:\n",
    "            exists.append(False)\n",
    "        else:\n",
    "            exists.append(True)\n",
    "        \n",
    "df['basin_id'] = basins\n",
    "df['completed'] = exists\n",
    "df = df.reset_index()\n",
    "df = df[df['completed'] == True]\n",
    "\n",
    "basin_ids = df.basin_id.to_list()\n",
    "\n",
    "# Remove basin_ids that return nan values\n",
    "basin_ids.remove('18017')\n",
    "basin_ids.remove('18018')\n",
    "basin_ids.remove('54038')\n",
    "basin_ids.remove('76011')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64090e4-0f50-4c88-82bb-2a6e1e0f9432",
   "metadata": {},
   "source": [
    "# Prepare files for whole evaluation period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af27f92-455a-47e9-b81c-201a3dba11d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, basin_id in enumerate(basin_ids):\n",
    "    print(i, end='\\r')\n",
    "    \n",
    "    # Load simulation dataframe and adjust time\n",
    "    df_sim = pd.read_csv(f'{OUTPUT}/simulations/{basin_id}_wflow_calibrated_evaluation_simulations.csv')\n",
    "    df_sim['time'] = pd.to_datetime(df_sim['time'])\n",
    "    df_sim = df_sim.set_index('time')   \n",
    "    \n",
    "    # Load observation dataframe\n",
    "\n",
    "    df_obs = pd.read_csv(f'{OUTPUT}/observations/{basin_id}_wflow_calibrated_evaluation_observations.csv', parse_dates=True, index_col='date')\n",
    "    \n",
    "    # Select evaluation period (drop first year)\n",
    "    mask = (df_obs.index > start_date) & (df_obs.index <= end_date)\n",
    "    df_obs = df_obs.loc[mask]\n",
    "    \n",
    "    # Join dataframes and rename columns\n",
    "    df_eval = df_sim.join(df_obs.discharge_vol)\n",
    "    df_eval = df_eval.reset_index()\n",
    "    df_eval = df_eval.rename(columns={'time':'date', 'discharge_vol':'obs'})\n",
    "    \n",
    "    if df_eval.columns[0] == 'index':\n",
    "        df_eval = df_eval.rename(columns={'index':'date'})\n",
    "    df_eval = df_eval.set_index('date')\n",
    "    \n",
    "    # Save Gumboot dataframe\n",
    "    df_eval.to_csv(f'{OUTPUT}/gumboot/{basin_id}_gumboot_wflow_calibrated_evaluation_simulations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d267af7-d684-4a58-b80d-8cb32c57c5e8",
   "metadata": {},
   "source": [
    "# Prepare Files per flow category evaluation period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c70c89-9f9e-49b9-9014-c3aa31673b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set flow categories based on percentiles\n",
    "flow_categories = {'low_flow': (5, 25),\n",
    "                   'mean_flow': (25, 75),\n",
    "                   'high_flow': (75, 95)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a09e8-1717-4cb1-97d0-6b53518348aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, basin_id in enumerate(basin_ids):\n",
    "    print(i, end='\\r')\n",
    "\n",
    "    for category in flow_categories:\n",
    "\n",
    "        # Load simulation dataframe and adjust time\n",
    "        df_sim = pd.read_csv(f'{OUTPUT}/flow_categories/{basin_id}_wflow_calibrated_evaluation_simulations_{category}.csv')\n",
    "        df_sim['date'] = pd.to_datetime(df_sim['date'])\n",
    "        df_sim = df_sim.set_index('date')   \n",
    "\n",
    "        # Load observation dataframe\n",
    "\n",
    "        df_obs = pd.read_csv(f'{OUTPUT}/observations/{basin_id}_wflow_calibrated_evaluation_observations_{category}.csv', parse_dates=True, index_col='date')\n",
    "\n",
    "        # Select evaluation period (drop first year)\n",
    "        mask = (df_obs.index > start_date) & (df_obs.index <= end_date)\n",
    "        df_obs = df_obs.loc[mask]\n",
    "\n",
    "        # Join dataframes and rename columns\n",
    "        df_eval = df_sim.join(df_obs.discharge_vol)\n",
    "        df_eval = df_eval.reset_index()\n",
    "        df_eval = df_eval.rename(columns={'discharge_vol':'obs'})\n",
    "\n",
    "        if df_eval.columns[0] == 'index':\n",
    "            df_eval = df_eval.rename(columns={'index':'date'})\n",
    "        df_eval = df_eval.set_index('date')\n",
    "\n",
    "        # Save Gumboot dataframe\n",
    "        df_eval.to_csv(f'{OUTPUT}/gumboot/{basin_id}_gumboot_wflow_calibrated_evaluation_simulations_{category}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
