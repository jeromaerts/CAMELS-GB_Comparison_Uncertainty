{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28e40945-78bb-4848-9cef-035c715f3d7e",
   "metadata": {},
   "source": [
    "# Wflow_SBM Calibrated, evaluation period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049d941c-4ee8-45e2-a732-f41b47ea33d7",
   "metadata": {},
   "source": [
    "# Select simulations that match flow categories that are based on observation percentiles\n",
    "## Calculate objective functions per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be4873-6d17-483e-8700-bdd3f78ea74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydroeval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6262465-e48c-4a3b-8159-2b43c96afc0f",
   "metadata": {},
   "source": [
    "## Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7b1fb1-8edc-4fb7-8d04-64a3a1f070bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "ROOT = Path(\"/gpfs/work1/0/wtrcycle/users/jaerts/camels_uk/\")\n",
    "MODELS = Path(f'{ROOT}/wflow/data/')\n",
    "AUXDATA = Path(f\"{ROOT}/aux_data\")\n",
    "OBSDIR = Path(f\"{AUXDATA}/CAMELS-GB/data/timeseries/\")\n",
    "OUTPUT = Path(f\"{ROOT}/results/wflow_sbm/evaluation_period_calibrated/\")\n",
    "\n",
    "# Set uncertainty estimate file\n",
    "uncertainty_file = f\"{AUXDATA}/CAMELS-GB/data/CAMELS_GB_hydrometry_attributes.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23f10b0-83ad-49f6-8aa1-c94b2f87a8dc",
   "metadata": {},
   "source": [
    "## Set Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980aae14-5ba8-4cd1-9640-1305382a284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get available basin IDs\n",
    "df_ids = pd.read_csv(f\"{AUXDATA}/CAMELS-GB/data/CAMELS_GB_topographic_attributes.csv\", index_col='gauge_id')\n",
    "basin_ids = df_ids.index.to_list()\n",
    "\n",
    "# Period (drop first year)\n",
    "start_date = '2008-10-01'\n",
    "end_date   = '2015-09-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff21ce5-c530-45a8-94c1-820c799e4d2c",
   "metadata": {},
   "source": [
    "## Select available results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf159e-9d54-4b5b-abdb-c56a16fdbdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "basins = []\n",
    "exists = []\n",
    "\n",
    "for basin_id in basin_ids:\n",
    "    basins.append(basin_id)\n",
    "\n",
    "    # check if file exists\n",
    "    sim_file = Path(f'{MODELS}/{basin_id}/evaluation/output.csv')\n",
    "    if sim_file.is_file() is False:\n",
    "        exists.append(False)\n",
    "    else:\n",
    "        df_sim = pd.read_csv(sim_file)\n",
    "    \n",
    "        # Check if csv containes output\n",
    "        if len(df_sim) == 0:\n",
    "            exists.append(False)\n",
    "        else:\n",
    "            exists.append(True)\n",
    "        \n",
    "df['basin_id'] = basins\n",
    "df['completed'] = exists\n",
    "df = df.reset_index()\n",
    "df = df[df['completed'] == True]\n",
    "\n",
    "basin_ids = df.basin_id.to_list()\n",
    "\n",
    "# Remove basin_ids that return nan values\n",
    "basin_ids.remove(18017)\n",
    "basin_ids.remove(18018)\n",
    "basin_ids.remove(54038)\n",
    "basin_ids.remove(76011)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf6c651-7d37-4a45-bdee-9cee63840194",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bec8fa9-f57b-4556-a221-3025d62875c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_objective_functions(basin_id, df_sim, df_obs):\n",
    "    \n",
    "    # Create empty dataframe and lists\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Combine obs and sim because of nan values\n",
    "    df_eval = df_obs.discharge_vol.to_frame().join(df_sim)\n",
    "    df_eval = df_eval.dropna()\n",
    "    \n",
    "    # Calculate objective functions and round\n",
    "    nse = hydroeval.evaluator(hydroeval.nse, df_eval[f'evaluation'], df_eval.discharge_vol, axis=1)\n",
    "    nse = np.round(nse[0], 4)\n",
    "\n",
    "    kge_2009 = hydroeval.evaluator(hydroeval.kge, df_eval[f'evaluation'], df_eval.discharge_vol, axis=1)\n",
    "    kge_2009 = np.round(kge_2009[0][0], 4)\n",
    "\n",
    "    kge_2012 = hydroeval.evaluator(hydroeval.kgeprime, df_eval[f'evaluation'], df_eval.discharge_vol, axis=1)\n",
    "    kge_2012 = np.round(kge_2012[0][0], 4)\n",
    "\n",
    "    kge_np = hydroeval.evaluator(hydroeval.kgenp, df_eval[f'evaluation'], df_eval.discharge_vol, axis=1)\n",
    "    kge_np_value = np.round(kge_np[0][0], 4)\n",
    "    kge_np_r = np.round(kge_np[0][1], 4)\n",
    "    kge_np_alpha = np.round(kge_np[0][2], 4)\n",
    "    kge_np_beta = np.round(kge_np[0][3], 4)\n",
    "\n",
    "    df['basin_id'] = [basin_id]\n",
    "    df['nse']      = [nse]\n",
    "    df['kge_2009'] = [kge_2009]\n",
    "    df['kge_2012'] = [kge_2012]\n",
    "    df['kge_np']   = [kge_np_value]\n",
    "\n",
    "    df['kge_np_r'] = [kge_np_r]\n",
    "    df['kge_np_alpha'] = [kge_np_alpha]\n",
    "    df['kge_np_beta'] = [kge_np_beta]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b31c3fa-6b7d-4e29-af7b-839f2c4786bc",
   "metadata": {},
   "source": [
    "## Load uncertainty estimates and drop nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb226fb-1e6b-4441-9364-8d81843c2150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load uncertainty file and drop nan\n",
    "df_uncertainty = pd.read_csv(uncertainty_file, index_col='gauge_id')\n",
    "\n",
    "df_uncertainty = df_uncertainty[df_uncertainty['q5_uncert_upper'].notna()]\n",
    "df_uncertainty = df_uncertainty[df_uncertainty['q5_uncert_lower'].notna()]\n",
    "df_uncertainty = df_uncertainty[df_uncertainty['q95_uncert_upper'].notna()]\n",
    "df_uncertainty = df_uncertainty[df_uncertainty['q95_uncert_lower'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b319201f-dde4-477a-823a-2695922f7b36",
   "metadata": {},
   "source": [
    "## Calculate observation timeseries based percentiles\n",
    "### Select sim based on obs percentiles\n",
    "### Calculate objective functions per percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb0403-5558-405b-b91c-52ef4fe35a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set flow categories based on percentiles\n",
    "flow_categories = {'low_flow': (5, 25),\n",
    "                   'mean_flow': (25, 75),\n",
    "                   'high_flow': (75, 95)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0325be-1e10-43ce-993c-420dd225cc0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for basin_id in basin_ids:\n",
    "    print(basin_id)\n",
    "    # Get model simulation timeseries\n",
    "    df_model = pd.read_csv(f\"{OUTPUT}/simulations/{basin_id}_wflow_calibrated_evaluation_simulations.csv\", index_col='time')\n",
    "\n",
    "    # Get obervation timeseries\n",
    "    df_obs = pd.read_csv(f'{OBSDIR}/CAMELS_GB_hydromet_timeseries_{basin_id}_19701001-20150930.csv', index_col='date')\n",
    "\n",
    "    # Select evaluation period\n",
    "    mask = (df_obs.index >= start_date) & (df_obs.index <= end_date)\n",
    "    df_obs = df_obs.loc[mask]\n",
    "\n",
    "    # Drop NaN values observation timeseries\n",
    "    df_obs = df_obs[df_obs['discharge_vol'].notna()]\n",
    "\n",
    "    # Loop Flow Categories\n",
    "    for category in flow_categories:\n",
    "\n",
    "        # Calculate percentiles\n",
    "        lower = flow_categories[category][0]\n",
    "        upper = flow_categories[category][1]\n",
    "\n",
    "        obs_perc_lower = np.percentile(df_obs.discharge_vol,lower,axis=0)\n",
    "        obs_perc_upper = np.percentile(df_obs.discharge_vol,upper,axis=0)\n",
    "\n",
    "        # Select observations based on percentiles\n",
    "        mask = (df_obs.discharge_vol >= obs_perc_lower) & (df_obs.discharge_vol <= obs_perc_upper)\n",
    "        df_obs_selected = df_obs.loc[mask]\n",
    "\n",
    "        # Select simulations that match observation based flow category\n",
    "        df_sim_selected = df_obs_selected.join(df_model)\n",
    "        df_sim_selected = df_sim_selected[['evaluation']]\n",
    "\n",
    "        # Export selected simulations\n",
    "        df_sim_selected.to_csv(f'{OUTPUT}/flow_categories/{basin_id}_wflow_calibrated_evaluation_simulations_{category}.csv')\n",
    "\n",
    "        # Export selected observation\n",
    "        df_obs_selected = df_obs_selected[['discharge_vol']]\n",
    "        df_obs_selected.to_csv(f'{OUTPUT}/observations/{basin_id}_wflow_calibrated_evaluation_observations_{category}.csv')\n",
    "        \n",
    "        # Calculate objective function for each water year and take average\n",
    "        years = list(range(int(start_date[:4]), int(end_date[:4])))\n",
    "\n",
    "        objective_dfs = []\n",
    "        for year in years:\n",
    "            start_year = f'{year}-10-01'\n",
    "            end_year = f'{year+1}-09-30'\n",
    "\n",
    "            # Select water year\n",
    "            mask_sim = (df_sim_selected.index >= start_year) & (df_sim_selected.index <= end_year)\n",
    "            mask_obs = (df_obs_selected.index >= start_year) & (df_obs_selected.index <= end_year)\n",
    "\n",
    "            df_sim_year = df_sim_selected.loc[mask_sim]\n",
    "            df_obs_year = df_obs_selected.loc[mask_obs]\n",
    "\n",
    "            # Calculate objective function\n",
    "            df_objective = calculate_objective_functions(basin_id, df_sim_year, df_obs_year)\n",
    "            objective_dfs.append(df_objective)\n",
    "\n",
    "        # Merge water years objective values and take the mean value\n",
    "        df = pd.concat(objective_dfs,axis=1)\n",
    "        df = df.groupby(level=0,axis=1).mean()\n",
    "        df = df.sort_values('kge_np', ascending=False)\n",
    "        df['basin_id'] = [basin_id] * len(df)\n",
    "        df.to_csv(f'{OUTPUT}/objective_functions/{basin_id}_wflow_calibrated_evaluation_objective_functions_{category}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e13c01-3026-4101-9b96-7503b60592df",
   "metadata": {},
   "source": [
    "# Create overview files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617fbb5-3918-44cb-8872-13cb21ca6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in flow_categories:\n",
    "\n",
    "    files = glob(f'{OUTPUT}/objective_functions/*_wflow_calibrated_evaluation_objective_functions_{category}.csv')\n",
    "\n",
    "    dataframes = []\n",
    "    \n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        dataframes.append(df)\n",
    "\n",
    "    df_out = pd.concat(dataframes)\n",
    "    df_out.to_csv(f'{ROOT}/results/wflow_sbm/wflow_calibrated_evaluation_objective_functions_overview_{category}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f634b4-f211-48a3-8344-6964bc976a55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
