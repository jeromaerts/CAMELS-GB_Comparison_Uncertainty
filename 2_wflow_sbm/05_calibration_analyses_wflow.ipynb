{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d75acc62-28fb-4a6b-85c2-2e6c998298b2",
   "metadata": {},
   "source": [
    "# Calibration analyses wflow_sbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d7393-56fa-4ae8-a442-4a5ff939af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import hydroeval\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45265902-e344-415e-adfc-f220ddd444ae",
   "metadata": {},
   "source": [
    "## Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19fb3b-1f23-4f99-9c0c-cfab737e3aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "ROOT = Path(\"/gpfs/work1/0/wtrcycle/users/jaerts/camels_uk/\")\n",
    "MODELS = Path(f'{ROOT}/wflow/data/')\n",
    "AUXDATA = Path(f\"{ROOT}/aux_data\")\n",
    "OBSDIR = Path(f\"{AUXDATA}/CAMELS-GB/data/timeseries/\")\n",
    "OUTPUT = Path(f\"{ROOT}/results/wflow_sbm/calibration_period/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2feb48c-ca96-4a3e-a182-9ac12183d106",
   "metadata": {},
   "source": [
    "## Set Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282e59b-cfd4-40d0-a5d5-69a10792d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get available basin IDs wflow_sbm\n",
    "basin_dirs = glob(f'{MODELS}/*')\n",
    "basin_ids = [s.split('/')[-1] for s in basin_dirs]\n",
    "basin_ids.sort()\n",
    "\n",
    "# Period (drop first year)\n",
    "start_date = '2001-10-01'\n",
    "end_date   = '2007-09-30'\n",
    "\n",
    "# Calibration Values\n",
    "calibration_values = [1,5,10,15,20,\n",
    "                      25,30,35,40,45,\n",
    "                      50,55,60,65,70,\n",
    "                      75,80,85,90,95,\n",
    "                      100,125,150,175,\n",
    "                      200,225,250,275,\n",
    "                      300,350,400,450,550,\n",
    "                      600,650,700,750,800,\n",
    "                      850,900,950,1000,1500,\n",
    "                      2000,2500,3000,4000,\n",
    "                      4500,5000,7500,10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab080a4-d6f2-481c-8a93-53ea1920cd30",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eec4b0-f5bc-4897-a6b0-71fdbacefafb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_simulations(basin_id, calibration_values, start_date, end_date):\n",
    "    dataframes = []\n",
    "\n",
    "    for calibration_value in calibration_values:\n",
    "        # Set simulation file\n",
    "        sim_file = glob(f'{MODELS}/{basin_id}/ksathorfrac_{calibration_value}/output.csv')[0]\n",
    "\n",
    "        # Load simulation dataframe\n",
    "        df = pd.read_csv(sim_file, parse_dates=True, index_col='time')\n",
    "\n",
    "        # Select calibration period (drop first year)\n",
    "        mask = (df.index >= start_date) & (df.index <= end_date)\n",
    "        df = df.loc[mask]\n",
    "        \n",
    "        # Rename column\n",
    "        df = df.rename(columns={'Q_1': f'ksathorfrac_{calibration_value}'})\n",
    "        \n",
    "        # Append to list\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Concat simulation dataframes\n",
    "    df_sim = pd.concat(dataframes,  axis=1, ignore_index=False)\n",
    "    \n",
    "    return df_sim\n",
    "\n",
    "\n",
    "def get_observations(basin_id, start_date, end_date):\n",
    "    # Set observation file\n",
    "    obs_file = glob(f'{OBSDIR}/*_{basin_id}_*.csv')[0]\n",
    "    \n",
    "    # Load observation dataframe\n",
    "    df_obs = pd.read_csv(obs_file, parse_dates=True, index_col='date')\n",
    "    \n",
    "    # Select calibration period (drop first year)\n",
    "    mask = (df_obs.index >= start_date) & (df_obs.index <= end_date)\n",
    "    df_obs = df_obs.loc[mask]\n",
    "    \n",
    "    return df_obs\n",
    "    \n",
    "def calculate_objective_functions(basin_id, df_sim, df_obs, calibration_values):\n",
    "\n",
    "    # Create empty dataframe and lists\n",
    "    df = pd.DataFrame()\n",
    "    basin_ids = []\n",
    "    ksathorfracs = []\n",
    "    nse_values = []\n",
    "    kge_2009_values = []\n",
    "    kge_2012_values = []\n",
    "    kge_np_values = []\n",
    "    kge_np_r_values = []\n",
    "    kge_np_alpha_values = []\n",
    "    kge_np_beta_values = []\n",
    "\n",
    "    # Calculate objective functions for each parameter value\n",
    "    for calibration_value in calibration_values:\n",
    "\n",
    "        basin_ids.append(basin_id)\n",
    "        ksathorfracs.append(calibration_value)\n",
    "\n",
    "        # Calculate objective functions and round\n",
    "        nse = hydroeval.evaluator(hydroeval.nse, df_sim[f'ksathorfrac_{calibration_value}'], df_obs.discharge_vol, axis=1)\n",
    "        nse_values.append(np.round(nse[0], 4))\n",
    "\n",
    "        kge_2009 = hydroeval.evaluator(hydroeval.kge, df_sim[f'ksathorfrac_{calibration_value}'], df_obs.discharge_vol, axis=1)\n",
    "        kge_2009_values.append(np.round(kge_2009[0][0], 4))\n",
    "\n",
    "        kge_2012 = hydroeval.evaluator(hydroeval.kgeprime, df_sim[f'ksathorfrac_{calibration_value}'], df_obs.discharge_vol, axis=1)\n",
    "        kge_2012_values.append(np.round(kge_2012[0][0], 4))    \n",
    "\n",
    "        kge_np = hydroeval.evaluator(hydroeval.kgenp, df_sim[f'ksathorfrac_{calibration_value}'], df_obs.discharge_vol, axis=1)\n",
    "        kge_np_values.append(np.round(kge_np[0][0], 4))    \n",
    "        kge_np_r_values.append(np.round(kge_np[0][1], 4))\n",
    "        kge_np_alpha_values.append(np.round(kge_np[0][2], 4))\n",
    "        kge_np_beta_values.append(np.round(kge_np[0][3], 4))\n",
    "    \n",
    "    df['basin_id'] = basin_ids\n",
    "    df['ksathorfrac'] = ksathorfracs\n",
    "    df['nse'] = nse_values\n",
    "    df['kge_2009'] = kge_2009_values\n",
    "    df['kge_2012'] = kge_2012_values\n",
    "    df['kge_np'] = kge_np_values\n",
    "    df['kge_np_r'] = kge_np_r_values\n",
    "    df['kge_np_alpha'] = kge_np_alpha_values\n",
    "    df['kge_np_beta'] = kge_np_beta_values\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29da805-7761-48c9-a277-538d9a4eb39e",
   "metadata": {},
   "source": [
    "# Check if output exists\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c8f638-ac23-4160-a7c9-25afbd45edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "basins = []\n",
    "exists = []\n",
    "\n",
    "for basin_id in basin_ids:\n",
    "    basins.append(basin_id)\n",
    "\n",
    "    # check if file exists\n",
    "    sim_file = Path(f'{MODELS}/{basin_id}/ksathorfrac_5/output.csv')\n",
    "    if sim_file.is_file() is False:\n",
    "        exists.append(False)\n",
    "    else:\n",
    "        df_sim = pd.read_csv(sim_file)\n",
    "    \n",
    "        # Check if csv containes output\n",
    "        if len(df_sim) < 3200:\n",
    "            exists.append(False)\n",
    "        else:\n",
    "            exists.append(True)\n",
    "        \n",
    "df['basin_id'] = basins\n",
    "df['completed'] = exists\n",
    "df = df.reset_index()\n",
    "\n",
    "# completed!\n",
    "df = df[df['completed'] == True]\n",
    "\n",
    "basin_ids = df.basin_id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a1b2d7-8478-4506-9647-106af01e369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(basin_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c915a61-2ae4-41ef-9917-335559d9466a",
   "metadata": {},
   "source": [
    "# Calculate objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b839bb9a-e443-4f0f-bd39-0e36a0a9be68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get sim and obs timeseries\n",
    "for basin_id in basin_ids:\n",
    "    print(basin_id)\n",
    "    \n",
    "    df_sim = get_simulations(basin_id, calibration_values, start_date, end_date)\n",
    "    df_obs = get_observations(basin_id, start_date, end_date)\n",
    "    \n",
    "    df_sim.to_csv(f'{OUTPUT}/simulations/{basin_id}_wflow_calibration_simulations.csv')\n",
    "    df_obs.to_csv(f'{OUTPUT}/observations/{basin_id}_wflow_calibration_observations.csv', index=False)   \n",
    "    \n",
    "    # Calculate objective function for each water year and take average\n",
    "    years = list(range(int(start_date[:4]), int(end_date[:4])))\n",
    "     \n",
    "    objective_dfs = []\n",
    "    for year in years:\n",
    "        start_year = f'{year}-10-01'\n",
    "        end_year = f'{year+1}-09-30'\n",
    "        \n",
    "        # Select water year\n",
    "        mask = (df_sim.index >= start_year) & (df_sim.index <= end_year)\n",
    "        df_sim_year = df_sim.loc[mask]\n",
    "        df_obs_year = df_obs.loc[mask]\n",
    "\n",
    "        # Calculate objective function\n",
    "        df_objective = calculate_objective_functions(basin_id, df_sim_year, df_obs_year, calibration_values)\n",
    "        objective_dfs.append(df_objective)\n",
    "    \n",
    "    # Merge water years objective values and take the mean value\n",
    "    df = pd.concat(objective_dfs,axis=1)\n",
    "    df = df.groupby(level=0,axis=1).mean()\n",
    "    df = df.sort_values('kge_np', ascending=False)\n",
    "    df['basin_id'] = [basin_id] * len(df)\n",
    "    df.to_csv(f'{OUTPUT}/objective_functions/{basin_id}_wflow_calibration_objective_functions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae213a5-13fb-401d-b536-04c8cf8de185",
   "metadata": {},
   "source": [
    "# Create overview dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0bd770-42d8-4024-ab83-8e111e53cb14",
   "metadata": {},
   "source": [
    "## Select the lowest ksathorfrac values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d82b6-4cc1-4334-b3e9-f21833db87e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create empty dataframe and lists\n",
    "df_out = pd.DataFrame()\n",
    "basins = []\n",
    "ls_ksathorfrac = []\n",
    "ls_kge_np = []\n",
    "ls_kge_np_r = []\n",
    "ls_kge_np_alpha = []\n",
    "ls_kge_np_beta = []\n",
    "ls_kge_2009 = []\n",
    "ls_kge_2012 = []\n",
    "ls_nse = []\n",
    "\n",
    "# Remove basin_ids that return nan values\n",
    "basin_ids.remove('18017')\n",
    "basin_ids.remove('18018')\n",
    "basin_ids.remove('54038')\n",
    "basin_ids.remove('76011')\n",
    "\n",
    "for basin_id in basin_ids:\n",
    "    print(basin_id)\n",
    "    file = glob(f\"{OUTPUT}/objective_functions/{basin_id}_wflow_calibration_objective_functions.csv\")[0]\n",
    "    # Read results and rank descending (kge_np)\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.set_index('kge_np')\n",
    "    df = df.sort_index(ascending=False)\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # Select lowest ksathorfrac within 0.02 of max KGE-NP\n",
    "    mask = (df.kge_np <= df.kge_np.max()) & (df.kge_np >= df.kge_np.max() - 0.02)\n",
    "    df = df.loc[mask]\n",
    "    df = df.sort_values(by='ksathorfrac')\n",
    "    df = df.loc[0]\n",
    "    \n",
    "    # Append results\n",
    "    basins.append(int(df['basin_id']))\n",
    "    ls_ksathorfrac.append(int(df['ksathorfrac']))\n",
    "    ls_kge_np.append(df['kge_np'])\n",
    "    ls_kge_np_r.append(df['kge_np_r'])\n",
    "    ls_kge_np_alpha.append(df['kge_np_alpha'])\n",
    "    ls_kge_np_beta.append(df['kge_np_beta'])\n",
    "    ls_kge_2009.append(df['kge_2009'])\n",
    "    ls_kge_2012.append(df['kge_2012'])\n",
    "    ls_nse.append(df['nse'])\n",
    "\n",
    "# Create output dataframe\n",
    "df_out['basin_id'] = basins    \n",
    "df_out['ksathorfrac'] = ls_ksathorfrac    \n",
    "df_out['kge_np'] = ls_kge_np    \n",
    "df_out['kge_np_r'] = ls_kge_np_r    \n",
    "df_out['kge_np_alpha'] = ls_kge_np_alpha    \n",
    "df_out['kge_np_beta'] = ls_kge_np_beta    \n",
    "df_out['kge_2009'] = ls_kge_2009    \n",
    "df_out['kge_2012'] = ls_kge_2012    \n",
    "df_out['nse'] = ls_nse \n",
    "\n",
    "# Write output\n",
    "df_out.to_csv(f'{ROOT}/results/wflow_sbm/wflow_calibration_objective_function_overview.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad020ad-b97f-4cb8-9bec-4f715cf20141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
