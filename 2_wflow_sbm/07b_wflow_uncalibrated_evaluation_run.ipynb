{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "207ca3b5-a90b-4596-8b0d-2e53f50b26e8",
   "metadata": {},
   "source": [
    "# Evaluation run wflow_sbm uncalibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1ae7b-a5dc-46f3-9567-1bde426bfaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from pathos.threading import ThreadPool as Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecfd8c1-03fc-4a5c-8751-505266bc7645",
   "metadata": {},
   "source": [
    "# Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafece79-606b-4a06-9e4e-c35af10067f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "ROOT = Path('/gpfs/work1/0/wtrcycle/users/jaerts/camels_uk/')\n",
    "MODELS = Path(f'{ROOT}/wflow/data/')\n",
    "RESULTS = Path(f'{ROOT}/results/')\n",
    "julia_path = '/gpfs/home6/jaerts/julia-1.7.3/bin/julia'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc29da4-dd87-49d7-a9ea-7d9f8668798e",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc94483-91ed-4188-9454-e63863b9de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get available basin IDs wflow_sbm\n",
    "calibration_file = f\"{RESULTS}/wflow_sbm/calibration_overview_wflow.csv\"\n",
    "df = pd.read_csv(calibration_file, index_col='basin_id')\n",
    "basin_ids = df.index.to_list()\n",
    "\n",
    "# Set available cores\n",
    "cores_available = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec4254d-6ef7-4fa6-b937-ce4df0091788",
   "metadata": {},
   "source": [
    "# Sort basins by size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd6ba0f-af14-4488-886a-2af5db080929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by basin size\n",
    "def sort_basin_ids_by_size(basin_ids):\n",
    "    sizes = []\n",
    "    for basin_id in basin_ids:\n",
    "        size = os.path.getsize(f'{MODELS}/{basin_id}/staticmaps.nc')\n",
    "        sizes.append(size)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['basin_id'] = basin_ids\n",
    "    df['size'] = sizes\n",
    "    df = df.sort_values('size')\n",
    "\n",
    "    basin_ids = df.basin_id.to_list()\n",
    "    \n",
    "    return basin_ids\n",
    "\n",
    "basin_ids_sorted = sort_basin_ids_by_size(basin_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70cb29-cf03-4658-8ac3-d67169850a4f",
   "metadata": {},
   "source": [
    "# Check if output exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5546a-0828-4654-a38e-247e87422a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "basins = []\n",
    "exists = []\n",
    "\n",
    "for basin_id in basin_ids_sorted:\n",
    "    basins.append(basin_id)\n",
    "\n",
    "    # check if file exists\n",
    "    sim_file = Path(f'{MODELS}/{basin_id}/evaluation/output.csv')\n",
    "    if sim_file.is_file() is False:\n",
    "        exists.append(False)\n",
    "    else:\n",
    "        df_sim = pd.read_csv(sim_file)\n",
    "    \n",
    "        # Check if csv containes output\n",
    "        if len(df_sim) < 2000:\n",
    "            exists.append(False)\n",
    "        else:\n",
    "            exists.append(True)\n",
    "        \n",
    "df['basin_id'] = basins\n",
    "df['completed'] = exists\n",
    "df = df.reset_index()\n",
    "df = df[df['completed'] == True]\n",
    "\n",
    "basin_ids_sorted = df.basin_id.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc099f5-cda5-4321-b20b-f59b8408bca1",
   "metadata": {},
   "source": [
    "# Create lists and run function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad30615-10de-4794-9b73-90e930eba1c5",
   "metadata": {},
   "source": [
    "# Evaluation run not calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee814e15-95f6-4e3f-8d15-e0b4e43558a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wflow_runner_evaluation(julia_path, basin_id):\n",
    "    print(f'Starting: {basin_id}')\n",
    "    \n",
    "    # Set config_file\n",
    "    config_file = f'{MODELS}/{basin_id}/wflow_sbm_evaluation_ksathorfrac_100.toml'\n",
    "    \n",
    "    # Call wflow julia command line\n",
    "    subprocess.call(\n",
    "                    f'{julia_path} -e \"using Wflow; Wflow.run()\" {config_file}',\n",
    "                    stdout=subprocess.DEVNULL,\n",
    "                    stderr=subprocess.STDOUT,\n",
    "                    shell=True\n",
    "                   )\n",
    "    \n",
    "    return print(f'Finished: {basin_id}')\n",
    "    \n",
    "def parallel_run(julia_path, basin_ids, threads=cores_available):\n",
    "    \n",
    "    # Set number of threads (cores) used for parallel run and map threads\n",
    "    if threads is None:\n",
    "        pool = Pool()\n",
    "    else:\n",
    "        pool = Pool(nodes=threads)\n",
    "        \n",
    "    # Run parallel models\n",
    "    pool.map(wflow_runner_evaluation, julia_paths, basin_ids)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccca4b4-a6ba-4637-bf49-75ae480525f0",
   "metadata": {},
   "source": [
    "# Check if output exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4158c291-90a4-44e3-824a-44ff860bf8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "basins = []\n",
    "exists = []\n",
    "\n",
    "for basin_id in basin_ids_sorted:\n",
    "    basins.append(basin_id)\n",
    "\n",
    "    # check if file exists\n",
    "    sim_file = Path(f'{MODELS}/{basin_id}/evaluation/output.csv')\n",
    "    if sim_file.is_file() is False:\n",
    "        exists.append(False)\n",
    "    else:\n",
    "        df_sim = pd.read_csv(sim_file)\n",
    "    \n",
    "        # Check if csv containes output\n",
    "        if len(df_sim) < 2000:\n",
    "            exists.append(False)\n",
    "        else:\n",
    "            exists.append(True)\n",
    "        \n",
    "df['basin_id'] = basins\n",
    "df['completed'] = exists\n",
    "df = df.reset_index()\n",
    "df = df[df['completed'] == True]\n",
    "\n",
    "basin_ids_sorted = df.basin_id.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a8ca0-fceb-4870-9562-459f983ca4b5",
   "metadata": {},
   "source": [
    "# Create lists and run functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6b1c3-e069-4ab6-9417-680f7099031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "julia_paths = [julia_path] * len(basin_ids_sorted)\n",
    "parallel_run(julia_paths, basins_redo, threads=cores_available)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
